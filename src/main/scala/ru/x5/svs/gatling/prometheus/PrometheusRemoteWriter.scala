package ru.x5.svs.gatling.prometheus

import org.slf4j.LoggerFactory
import java.util.concurrent.{ScheduledExecutorService, Executors, TimeUnit}
import scala.concurrent.ExecutionContext
// import ru.x5.svs.gatling.prometheus.infrastructure.ThreadSafeExecutorPool
// import ru.x5.svs.gatling.prometheus.monitoring.ThreadMonitor

/**
 * ÐžÐ Ð˜Ð“Ð˜ÐÐÐ›Ð¬ÐÐ«Ð™ PrometheusRemoteWriter - Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² Victoria Metrics
 */
class PrometheusRemoteWriter(
  private val victoriaMetricsUrl: String,
  private val testId: String,
  private val pod: String,
  private val pushIntervalSeconds: Int = 5
)(implicit private val ec: ExecutionContext) {

  private val logger = LoggerFactory.getLogger(classOf[PrometheusRemoteWriter])
  
  // ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—Ð˜Ð ÐžÐ’ÐÐÐÐ«Ð™ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð´Ð»Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
  private val scheduler: ScheduledExecutorService = Executors.newScheduledThreadPool(2)
  private val running = new java.util.concurrent.atomic.AtomicBoolean(false)
  
  // THREAD-SAFE Ð¿ÑƒÐ» Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼
  // private val metricsProcessor = new ThreadSafeExecutorPool(
  //   name = "PrometheusMetricsProcessor",
  //   corePoolSize = Math.max(2, Runtime.getRuntime.availableProcessors() / 2),
  //   maxPoolSize = Math.max(4, Runtime.getRuntime.availableProcessors()),
  //   queueCapacity = 1000
  // )
  
  /**
   * Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÑƒ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
   */
  def start(): Unit = {
    if (running.compareAndSet(false, true)) {
      logger.info(s"ORIGINAL PrometheusRemoteWriter: Starting periodic export to $victoriaMetricsUrl")
      
      // Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²
      // ThreadMonitor.startMonitoring()
      
      try {
        // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        val intervalSeconds = pushIntervalSeconds
        val scheduledFuture = scheduler.scheduleAtFixedRate(
          new Runnable {
            override def run(): Unit = {
              // ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐÐ¯ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¼ÐµÑ‚Ñ€Ð¸Ðº
              try {
                logger.info(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: SCHEDULER TRIGGERED! Thread: ${Thread.currentThread().getName}")
                sendMetrics()
                logger.info(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: SCHEDULER COMPLETED successfully!")
              } catch {
                case e: Exception =>
                  logger.error(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: SCHEDULER ERROR: ${e.getMessage}", e)
              }
            }
          },
          intervalSeconds, intervalSeconds, TimeUnit.SECONDS
        )
        
        logger.info(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Started periodic export - scheduled task: $scheduledFuture")
        logger.info(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Scheduler is running: ${!scheduler.isShutdown}")
        
      } catch {
        case e: Exception =>
          logger.error(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: ERROR starting scheduler: ${e.getMessage}", e)
          running.set(false)
      }
    } else {
      logger.warn(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Already running, skipping start")
    }
  }
  
  /**
   * ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÑƒ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
   */
  def stop(): Unit = {
    if (running.compareAndSet(true, false)) {
      logger.info(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Stopping periodic export")
      
      // GRACEFUL SHUTDOWN Ð´Ð»Ñ Ð²ÑÐµÑ… Ð¿ÑƒÐ»Ð¾Ð² Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²
      logger.info("ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Shutting down thread pools...")
      
      // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº
      scheduler.shutdown()
      try {
        if (!scheduler.awaitTermination(3, java.util.concurrent.TimeUnit.SECONDS)) {
          logger.warn("ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Scheduler did not terminate gracefully, forcing shutdown")
          scheduler.shutdownNow()
        }
      } catch {
        case e: InterruptedException =>
          logger.warn("ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Interrupted while waiting for scheduler termination")
          scheduler.shutdownNow()
          Thread.currentThread().interrupt()
      }
      
      // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ THREAD-SAFE Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
      // metricsProcessor.shutdown()
      
      // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²
      // ThreadMonitor.stopMonitoring()
      
      // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¿Ñ€Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ
      logger.info(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Sending final metrics")
      sendMetrics()
      
      logger.info(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Stopped and sent final metrics")
    } else {
      logger.warn(s"ðŸ”¥ ORIGINAL PrometheusRemoteWriter: Already stopped or not running")
    }
  }
  
  /**
   * ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² Victoria Metrics Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
   */
  private def sendMetrics(): Unit = {
    // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ writer ÐµÑ‰Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
    if (!running.get()) {
      logger.warn(s"ðŸ“Š QUEUE: Writer is stopped, skipping metrics sending")
      return
    }
    
    try {
      logger.info(s"ðŸ“Š QUEUE: Starting batch metrics sending from queue")
      
      // ÐÐ• Ð˜Ð¡ÐŸÐžÐ›Ð¬Ð—Ð£Ð•Ðœ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ! Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸!
      val queueStats = MetricsQueue.getQueueStats()
      
      logger.info(s"ðŸ“Š QUEUE: Queue stats: $queueStats")
      
      // Ð’ÑÐµÐ³Ð´Ð° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (Ð½Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼ Ð¾Ñ‚ Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸)
      if (queueStats.httpRequestCount > 0 || queueStats.httpErrorCount > 0) {
        val managerOpt = PrometheusMetricsManager.getInstance
        
        managerOpt.foreach { manager =>
          logger.info(s"ðŸ“Š QUEUE: Processing metrics with manager...")
          
          // ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
          val httpRequestCounters = MetricsQueue.getHttpRequestCounters()
          val httpErrorCounters = MetricsQueue.getHttpErrorCounters()
          val httpDurations = MetricsQueue.getHttpDurations()
          
          // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² PrometheusMetricsManager
          manager.updateHttpMetricsFromQueue(httpRequestCounters, httpErrorCounters)
          
          // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ HTTP durations
          manager.updateHttpDurationsFromQueue(httpDurations)
          
          // Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
          manager.logSystemMetrics()
          
          // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Prometheus Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐ¾ Ð²ÑÐµÐ¼Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸
          val allMetrics = manager.createPrometheusFormat()
          logger.info(s"ðŸ“Š QUEUE: Created Prometheus format (${allMetrics.length} chars)")
          
          // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð² Victoria Metrics
          manager.sendToVictoriaMetrics(allMetrics)
          logger.info(s"ðŸ“Š QUEUE: Successfully sent batch metrics to Victoria Metrics!")
          
          // ÐÐ• ÐžÐ§Ð˜Ð©ÐÐ•Ðœ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ! Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸!
          // MetricsQueue.clearQueue() // Ð£Ð‘Ð ÐÐÐž - Ð½Ðµ Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ!
        }
      } else {
        logger.info(s"ðŸ“Š QUEUE: No metrics in queue, skipping batch send")
      }
      
    } catch {
      case e: Exception =>
        logger.error(s"ðŸ“Š QUEUE: Error sending batch metrics: ${e.getMessage}", e)
    }
  }
  
}

object PrometheusRemoteWriter {
  private var instance: Option[PrometheusRemoteWriter] = None
  
  def initialize(victoriaMetricsUrl: String, testId: String, pod: String)(implicit ec: ExecutionContext): PrometheusRemoteWriter = {
    instance = Some(new PrometheusRemoteWriter(victoriaMetricsUrl, testId, pod))
    instance.get
  }
  
  def getInstance: Option[PrometheusRemoteWriter] = instance
  
  def start(): Unit = {
    instance.foreach(_.start())
  }
  
  def stop(): Unit = {
    instance.foreach(_.stop())
  }
}
